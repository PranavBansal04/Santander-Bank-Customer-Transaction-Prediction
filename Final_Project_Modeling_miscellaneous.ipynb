{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "\n",
    "<h2><center><font size=\"4\">Dataset used: Santander Customer Transaction Prediction</font></center></h2>\n",
    "\n",
    "<br>\n",
    "\n",
    "# <a id='0'>Content</a>\n",
    "\n",
    "\n",
    "- <a href='#6'>Model</a>\n",
    "- <a href='#7'>Submission</a>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fa44d3d09a93efc6e27432ce40d412b781153a2f"
   },
   "source": [
    "# <a id='1'>Introduction</a>  \n",
    "\n",
    "In this challenge, Santander invites Kagglers to help them identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted. The data provided for this competition has the same structure as the real data they have available to solve this problem.  \n",
    "\n",
    "The data is anonimyzed, each row containing 200 numerical values identified just with a number.  \n",
    "\n",
    "In the following we will explore the data, prepare it for a model, train a model and predict the target value for the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f4c5d0b42a79c143d4b1a0423b0c51265fd718fd"
   },
   "source": [
    "# <a id='2'>Prepare for data analysis</a>  \n",
    "\n",
    "\n",
    "## Load packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "2041989e97107b61bb6659706ead46cc448c8e9e",
    "execution": {
     "iopub.execute_input": "2023-02-06T08:54:53.647187Z",
     "iopub.status.busy": "2023-02-06T08:54:53.646524Z",
     "iopub.status.idle": "2023-02-06T08:54:53.654169Z",
     "shell.execute_reply": "2023-02-06T08:54:53.653273Z",
     "shell.execute_reply.started": "2023-02-06T08:54:53.647112Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "warnings.filterwarnings('ignore')\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "13cdc14c0a53b11fd7438a87bff04335666a5482"
   },
   "source": [
    "## Load data   \n",
    "\n",
    "Let's check what data files are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "80167a92eedaecb6878667e35c55e4dbf8d3dc20",
    "execution": {
     "iopub.execute_input": "2023-02-06T08:54:59.257945Z",
     "iopub.status.busy": "2023-02-06T08:54:59.257161Z",
     "iopub.status.idle": "2023-02-06T08:54:59.278240Z",
     "shell.execute_reply": "2023-02-06T08:54:59.277253Z",
     "shell.execute_reply.started": "2023-02-06T08:54:59.257877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.csv', 'train.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH=\"./data/\"\n",
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a37cbcca50a9993268b90dbb9ab6ddb72be0632c"
   },
   "source": [
    "Let's load the train and test data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "cdd6627b37c9b162dd2d7f677576c94e35571fd8",
    "execution": {
     "iopub.execute_input": "2023-02-06T08:55:01.876362Z",
     "iopub.status.busy": "2023-02-06T08:55:01.875699Z",
     "iopub.status.idle": "2023-02-06T08:55:18.070942Z",
     "shell.execute_reply": "2023-02-06T08:55:18.069651Z",
     "shell.execute_reply.started": "2023-02-06T08:55:01.876290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.77 s, sys: 233 ms, total: 8 s\n",
      "Wall time: 8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = pd.read_csv(PATH+\"train.csv\")\n",
    "test_df = pd.read_csv(PATH+\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    var_0    var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  test_0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493   \n",
       "1  test_1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196   \n",
       "2  test_2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950   \n",
       "3  test_3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397   \n",
       "4  test_4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595   \n",
       "\n",
       "     var_7   var_8  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.2675  2.1337  ...  -2.1556  11.8495  -1.4300   2.4508  13.7112   2.4669   \n",
       "1  18.6316 -4.4131  ...  10.6165   8.8349   0.9403  10.1282  15.5765   0.4773   \n",
       "2  20.2537  1.5233  ...  -0.7484  10.9935   1.9803   2.1800  12.9813   2.1281   \n",
       "3  20.5660  3.3755  ...   9.5702   9.0766   1.6580   3.5813  15.1874   3.1656   \n",
       "4  10.6048  2.9890  ...   4.2259   9.1723   1.2835   3.3778  19.5542  -0.2860   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   4.3654  10.7200  15.4722  -8.7197  \n",
       "1  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
       "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
       "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
       "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
       "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
       "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
       "\n",
       "    var_9  ...  var_190  var_191  var_192  var_193  var_194  var_195  var_196  \\\n",
       "0  5.7470  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   7.8784   \n",
       "1  8.0851  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   8.1267   \n",
       "2  5.9525  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417  -6.5213   \n",
       "3  8.2450  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706  -2.9275   \n",
       "4  7.6784  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   3.9267   \n",
       "\n",
       "   var_197  var_198  var_199  \n",
       "0   8.5635  12.7803  -1.0914  \n",
       "1   8.7889  18.3560   1.9518  \n",
       "2   8.2675  14.7222   0.3965  \n",
       "3  10.2922  17.9697  -8.9996  \n",
       "4   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_df.drop(['ID_code','target'],axis=1)\n",
    "test_data = test_df.drop(['ID_code'],axis=1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T10:11:07.059100Z",
     "iopub.status.busy": "2023-02-06T10:11:07.058752Z",
     "iopub.status.idle": "2023-02-06T10:11:09.165572Z",
     "shell.execute_reply": "2023-02-06T10:11:09.164504Z",
     "shell.execute_reply.started": "2023-02-06T10:11:07.059043Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(train_data)  \n",
    "x_test = scaler.transform(test_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T10:47:55.579146Z",
     "iopub.status.busy": "2023-02-06T10:47:55.578583Z",
     "iopub.status.idle": "2023-02-06T10:47:56.768328Z",
     "shell.execute_reply": "2023-02-06T10:47:56.767387Z",
     "shell.execute_reply.started": "2023-02-06T10:47:55.579094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB  \n",
    "classifier = GaussianNB()  \n",
    "classifier.fit(x_train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T10:48:00.212640Z",
     "iopub.status.busy": "2023-02-06T10:48:00.212107Z",
     "iopub.status.idle": "2023-02-06T10:48:01.467785Z",
     "shell.execute_reply": "2023-02-06T10:48:01.466721Z",
     "shell.execute_reply.started": "2023-02-06T10:48:00.212586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.921695"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(x_train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T10:42:11.532259Z",
     "iopub.status.busy": "2023-02-06T10:42:11.531591Z",
     "iopub.status.idle": "2023-02-06T10:42:12.833378Z",
     "shell.execute_reply": "2023-02-06T10:42:12.832038Z",
     "shell.execute_reply.started": "2023-02-06T10:42:11.531965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6754651025994682\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "x_train_pred = classifier.predict(x_train)\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(x_train, x_train_pred)\n",
    "# metrics.auc(fpr, tpr)\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(target,x_train_pred))\n",
    "fpr, tpr, thresholds = roc_curve(target,x_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T10:44:03.165379Z",
     "iopub.status.busy": "2023-02-06T10:44:03.164999Z",
     "iopub.status.idle": "2023-02-06T10:44:03.172484Z",
     "shell.execute_reply": "2023-02-06T10:44:03.171152Z",
     "shell.execute_reply.started": "2023-02-06T10:44:03.165310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6754651025994682"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic naive bayes with scaled features gave 0.67 AUC on training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T10:52:00.736964Z",
     "iopub.status.busy": "2023-02-06T10:52:00.736645Z",
     "iopub.status.idle": "2023-02-06T10:52:06.929253Z",
     "shell.execute_reply": "2023-02-06T10:52:06.928316Z",
     "shell.execute_reply.started": "2023-02-06T10:52:00.736915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7701693144045091"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_logistic = LogisticRegression(random_state=0).fit(X_over, y_over)\n",
    "clf_logistic.score(X_over, y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-06T10:53:05.099189Z",
     "iopub.status.busy": "2023-02-06T10:53:05.098886Z",
     "iopub.status.idle": "2023-02-06T10:53:05.286767Z",
     "shell.execute_reply": "2023-02-06T10:53:05.285722Z",
     "shell.execute_reply.started": "2023-02-06T10:53:05.099149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7701693144045092\n"
     ]
    }
   ],
   "source": [
    "x_train_pred = clf_logistic.predict(X_over)\n",
    "print(roc_auc_score(y_over,x_train_pred))\n",
    "fpr, tpr, thresholds = roc_curve(y_over,x_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression performs even worse than naive bayes in terms of AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count before oversampling:  \n",
      "Counter({0: 179902, 1: 20098})\n",
      "count ater oversampling : \n",
      "Counter({0: 179902, 1: 179902})\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "print(\"Count before oversampling:  \")\n",
    "print(Counter(target))\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "# oversample = RandomOverSampler(sampling_strategy=0.5)\n",
    "\n",
    "X_over, y_over = oversample.fit_resample(train_data, target)\n",
    "print(\"count ater oversampling : \")\n",
    "print(Counter(y_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8085290880590543\n",
      "0.8085290880590543\n"
     ]
    }
   ],
   "source": [
    "# Training Naive Bayes again on oversampled data\n",
    "\n",
    "x_train = scaler.fit_transform(X_over)\n",
    "classifier = GaussianNB()  \n",
    "classifier.fit(X_over, y_over)\n",
    "\n",
    "print(classifier.score(X_over, y_over))\n",
    "\n",
    "\n",
    "x_train_pred = classifier.predict(X_over)\n",
    "\n",
    "print(roc_auc_score(y_over,x_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After oversampling, AUC has significantly increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try SMOTE technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count before oversampling:  \n",
      "Counter({0: 179902, 1: 20098})\n",
      "count ater oversampling : \n",
      "Counter({0: 179902, 1: 179902})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"Count before oversampling:  \")\n",
    "print(Counter(target))\n",
    "oversample = SMOTE(random_state=1)\n",
    "# oversample = RandomOverSampler(sampling_strategy=0.5)\n",
    "\n",
    "X_over, y_over = oversample.fit_resample(train_data, target)\n",
    "print(\"count ater oversampling : \")\n",
    "print(Counter(y_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8655823726250959\n",
      "0.8655823726250957\n"
     ]
    }
   ],
   "source": [
    "# Training Naive Bayes again using SMOTE\n",
    "\n",
    "x_train = scaler.fit_transform(X_over)\n",
    "classifier = GaussianNB()  \n",
    "classifier.fit(X_over, y_over)\n",
    "\n",
    "print(classifier.score(X_over, y_over))\n",
    "\n",
    "\n",
    "x_train_pred = classifier.predict(X_over)\n",
    "x_test_predictions = classifier.predict(x_test)\n",
    "\n",
    "print(roc_auc_score(y_over,x_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier on Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_over,y_over)\n",
    "print(clf.score(X_over, y_over))\n",
    "x_train_pred = clf.predict(X_over)\n",
    "print(roc_auc_score(y_over,x_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree has overfitting, lets try Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7669536747784905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(max_depth=6, random_state=0)\n",
    "clf.fit(X_over,y_over)\n",
    "x_train_pred = clf.predict(X_over)\n",
    "print(roc_auc_score(y_over,x_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest performs worse than naive bayes on training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ac818e478d560bee541240eac9190ee5042eab48"
   },
   "source": [
    "# <a id='6'>Model</a>  \n",
    "\n",
    "From the train columns list, we drop the ID and target to form the features list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "567d06495fb26ca26881c0fb9a8ef80b388ab901"
   },
   "outputs": [],
   "source": [
    "features = [c for c in train_df.columns if c not in ['ID_code', 'target']]\n",
    "target = train_df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e48d029f6bf9421e401c0b2e3bfe269dfbad4e8"
   },
   "source": [
    "We define the hyperparameters for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "8a57bca14c4c82fb80bafd0c27c42bf1a405b531"
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.4,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.05,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,  \n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary', \n",
    "    'verbosity': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e93df12ae1b6e514da38772132fb35ef048d8e73"
   },
   "source": [
    "We run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "595ba3944cb9365e292819afcd8406de8166bd0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "[LightGBM] [Info] Number of positive: 18089, number of negative: 161911\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.339152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 53040\n",
      "[LightGBM] [Info] Number of data points in the train set: 180000, number of used features: 208\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\ttraining's auc: 0.885918\tvalid_1's auc: 0.875496\n",
      "[2000]\ttraining's auc: 0.903601\tvalid_1's auc: 0.887846\n",
      "[3000]\ttraining's auc: 0.914985\tvalid_1's auc: 0.894505\n",
      "[4000]\ttraining's auc: 0.922396\tvalid_1's auc: 0.898394\n",
      "[5000]\ttraining's auc: 0.928084\tvalid_1's auc: 0.900316\n",
      "[6000]\ttraining's auc: 0.932925\tvalid_1's auc: 0.901107\n",
      "[7000]\ttraining's auc: 0.937124\tvalid_1's auc: 0.901798\n",
      "[8000]\ttraining's auc: 0.941121\tvalid_1's auc: 0.902207\n",
      "[9000]\ttraining's auc: 0.944827\tvalid_1's auc: 0.90226\n",
      "[10000]\ttraining's auc: 0.948293\tvalid_1's auc: 0.90227\n",
      "[11000]\ttraining's auc: 0.951589\tvalid_1's auc: 0.902188\n",
      "Early stopping, best iteration is:\n",
      "[8864]\ttraining's auc: 0.944365\tvalid_1's auc: 0.902335\n",
      "Fold 1\n",
      "[LightGBM] [Info] Number of positive: 18089, number of negative: 161911\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53040\n",
      "[LightGBM] [Info] Number of data points in the train set: 180000, number of used features: 208\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\ttraining's auc: 0.886888\tvalid_1's auc: 0.866604\n",
      "[2000]\ttraining's auc: 0.904195\tvalid_1's auc: 0.880999\n",
      "[3000]\ttraining's auc: 0.91546\tvalid_1's auc: 0.889409\n",
      "[4000]\ttraining's auc: 0.922647\tvalid_1's auc: 0.893587\n",
      "[5000]\ttraining's auc: 0.92827\tvalid_1's auc: 0.895706\n",
      "[6000]\ttraining's auc: 0.933112\tvalid_1's auc: 0.897306\n",
      "[7000]\ttraining's auc: 0.937246\tvalid_1's auc: 0.898211\n",
      "[8000]\ttraining's auc: 0.941192\tvalid_1's auc: 0.898974\n",
      "[9000]\ttraining's auc: 0.944793\tvalid_1's auc: 0.899191\n",
      "[10000]\ttraining's auc: 0.948291\tvalid_1's auc: 0.899233\n",
      "[11000]\ttraining's auc: 0.95154\tvalid_1's auc: 0.899505\n",
      "[12000]\ttraining's auc: 0.954669\tvalid_1's auc: 0.899813\n",
      "[13000]\ttraining's auc: 0.957663\tvalid_1's auc: 0.899926\n",
      "[14000]\ttraining's auc: 0.960455\tvalid_1's auc: 0.899895\n",
      "[15000]\ttraining's auc: 0.963141\tvalid_1's auc: 0.89997\n",
      "[16000]\ttraining's auc: 0.965715\tvalid_1's auc: 0.89997\n",
      "[17000]\ttraining's auc: 0.968183\tvalid_1's auc: 0.89987\n",
      "[18000]\ttraining's auc: 0.970493\tvalid_1's auc: 0.899825\n",
      "Early stopping, best iteration is:\n",
      "[15152]\ttraining's auc: 0.963547\tvalid_1's auc: 0.900033\n",
      "Fold 2\n",
      "[LightGBM] [Info] Number of positive: 18088, number of negative: 161912\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53040\n",
      "[LightGBM] [Info] Number of data points in the train set: 180000, number of used features: 208\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\ttraining's auc: 0.887382\tvalid_1's auc: 0.868203\n",
      "[2000]\ttraining's auc: 0.904306\tvalid_1's auc: 0.882055\n",
      "[3000]\ttraining's auc: 0.915434\tvalid_1's auc: 0.890143\n",
      "[4000]\ttraining's auc: 0.922772\tvalid_1's auc: 0.893861\n",
      "[5000]\ttraining's auc: 0.928473\tvalid_1's auc: 0.896232\n",
      "[6000]\ttraining's auc: 0.933254\tvalid_1's auc: 0.897543\n",
      "[7000]\ttraining's auc: 0.937529\tvalid_1's auc: 0.898195\n",
      "[8000]\ttraining's auc: 0.941343\tvalid_1's auc: 0.898669\n",
      "[9000]\ttraining's auc: 0.945013\tvalid_1's auc: 0.898899\n",
      "[10000]\ttraining's auc: 0.948504\tvalid_1's auc: 0.89913\n",
      "[11000]\ttraining's auc: 0.951747\tvalid_1's auc: 0.899319\n",
      "[12000]\ttraining's auc: 0.954837\tvalid_1's auc: 0.899497\n",
      "[13000]\ttraining's auc: 0.957873\tvalid_1's auc: 0.899286\n",
      "[14000]\ttraining's auc: 0.960679\tvalid_1's auc: 0.899318\n",
      "[15000]\ttraining's auc: 0.963338\tvalid_1's auc: 0.899339\n",
      "Early stopping, best iteration is:\n",
      "[12221]\ttraining's auc: 0.955531\tvalid_1's auc: 0.899566\n",
      "Fold 3\n",
      "[LightGBM] [Info] Number of positive: 18088, number of negative: 161912\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53040\n",
      "[LightGBM] [Info] Number of data points in the train set: 180000, number of used features: 208\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\ttraining's auc: 0.886749\tvalid_1's auc: 0.868607\n",
      "[2000]\ttraining's auc: 0.903931\tvalid_1's auc: 0.881884\n",
      "[3000]\ttraining's auc: 0.915344\tvalid_1's auc: 0.890143\n",
      "[4000]\ttraining's auc: 0.922698\tvalid_1's auc: 0.894413\n",
      "[5000]\ttraining's auc: 0.928358\tvalid_1's auc: 0.896822\n",
      "[6000]\ttraining's auc: 0.933238\tvalid_1's auc: 0.897951\n",
      "[7000]\ttraining's auc: 0.937509\tvalid_1's auc: 0.898734\n",
      "[8000]\ttraining's auc: 0.941468\tvalid_1's auc: 0.899095\n",
      "[9000]\ttraining's auc: 0.945112\tvalid_1's auc: 0.899143\n",
      "[10000]\ttraining's auc: 0.948588\tvalid_1's auc: 0.89939\n",
      "[11000]\ttraining's auc: 0.951797\tvalid_1's auc: 0.899325\n",
      "[12000]\ttraining's auc: 0.954886\tvalid_1's auc: 0.899423\n",
      "[13000]\ttraining's auc: 0.957829\tvalid_1's auc: 0.899483\n",
      "[14000]\ttraining's auc: 0.960602\tvalid_1's auc: 0.899512\n",
      "[15000]\ttraining's auc: 0.963286\tvalid_1's auc: 0.899411\n",
      "[16000]\ttraining's auc: 0.965835\tvalid_1's auc: 0.899376\n",
      "[17000]\ttraining's auc: 0.968251\tvalid_1's auc: 0.899182\n",
      "Early stopping, best iteration is:\n",
      "[14372]\ttraining's auc: 0.961646\tvalid_1's auc: 0.899556\n",
      "Fold 4\n",
      "[LightGBM] [Info] Number of positive: 18088, number of negative: 161912\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53040\n",
      "[LightGBM] [Info] Number of data points in the train set: 180000, number of used features: 208\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\ttraining's auc: 0.887541\tvalid_1's auc: 0.862847\n",
      "[2000]\ttraining's auc: 0.904642\tvalid_1's auc: 0.876539\n",
      "[3000]\ttraining's auc: 0.915775\tvalid_1's auc: 0.884622\n",
      "[4000]\ttraining's auc: 0.923012\tvalid_1's auc: 0.888898\n",
      "[5000]\ttraining's auc: 0.928717\tvalid_1's auc: 0.891203\n",
      "[6000]\ttraining's auc: 0.933474\tvalid_1's auc: 0.892861\n",
      "[7000]\ttraining's auc: 0.937661\tvalid_1's auc: 0.893679\n",
      "[8000]\ttraining's auc: 0.941538\tvalid_1's auc: 0.894032\n",
      "[9000]\ttraining's auc: 0.945165\tvalid_1's auc: 0.894334\n",
      "[10000]\ttraining's auc: 0.94863\tvalid_1's auc: 0.894506\n",
      "[11000]\ttraining's auc: 0.951885\tvalid_1's auc: 0.894658\n",
      "[12000]\ttraining's auc: 0.955023\tvalid_1's auc: 0.894724\n",
      "[13000]\ttraining's auc: 0.958019\tvalid_1's auc: 0.894865\n",
      "[14000]\ttraining's auc: 0.960825\tvalid_1's auc: 0.894765\n",
      "[15000]\ttraining's auc: 0.963561\tvalid_1's auc: 0.894811\n",
      "[16000]\ttraining's auc: 0.966135\tvalid_1's auc: 0.894789\n",
      "Early stopping, best iteration is:\n",
      "[13033]\ttraining's auc: 0.958107\tvalid_1's auc: 0.894905\n",
      "Fold 5\n",
      "[LightGBM] [Info] Number of positive: 18088, number of negative: 161912\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.267363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 53040\n",
      "[LightGBM] [Info] Number of data points in the train set: 180000, number of used features: 208\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\ttraining's auc: 0.886656\tvalid_1's auc: 0.869661\n",
      "[2000]\ttraining's auc: 0.904081\tvalid_1's auc: 0.883048\n",
      "[3000]\ttraining's auc: 0.915439\tvalid_1's auc: 0.890525\n",
      "[4000]\ttraining's auc: 0.922876\tvalid_1's auc: 0.894265\n",
      "[5000]\ttraining's auc: 0.928469\tvalid_1's auc: 0.89591\n",
      "[6000]\ttraining's auc: 0.933314\tvalid_1's auc: 0.897189\n",
      "[7000]\ttraining's auc: 0.937558\tvalid_1's auc: 0.897569\n",
      "[8000]\ttraining's auc: 0.941491\tvalid_1's auc: 0.897992\n",
      "[9000]\ttraining's auc: 0.945197\tvalid_1's auc: 0.898049\n",
      "[10000]\ttraining's auc: 0.948637\tvalid_1's auc: 0.898086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11000]\ttraining's auc: 0.951859\tvalid_1's auc: 0.898186\n",
      "[12000]\ttraining's auc: 0.955047\tvalid_1's auc: 0.898071\n",
      "[13000]\ttraining's auc: 0.958043\tvalid_1's auc: 0.898155\n",
      "Early stopping, best iteration is:\n",
      "[10356]\ttraining's auc: 0.949799\tvalid_1's auc: 0.898259\n",
      "Fold 6\n",
      "[LightGBM] [Info] Number of positive: 18088, number of negative: 161912\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53040\n",
      "[LightGBM] [Info] Number of data points in the train set: 180000, number of used features: 208\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\ttraining's auc: 0.886795\tvalid_1's auc: 0.868372\n",
      "[2000]\ttraining's auc: 0.903886\tvalid_1's auc: 0.881877\n",
      "[3000]\ttraining's auc: 0.915243\tvalid_1's auc: 0.889648\n",
      "[4000]\ttraining's auc: 0.92264\tvalid_1's auc: 0.893456\n",
      "[5000]\ttraining's auc: 0.928345\tvalid_1's auc: 0.895663\n",
      "[6000]\ttraining's auc: 0.933156\tvalid_1's auc: 0.897068\n",
      "[7000]\ttraining's auc: 0.937421\tvalid_1's auc: 0.897864\n",
      "[8000]\ttraining's auc: 0.941314\tvalid_1's auc: 0.898095\n",
      "[9000]\ttraining's auc: 0.945002\tvalid_1's auc: 0.898382\n",
      "[10000]\ttraining's auc: 0.948536\tvalid_1's auc: 0.898442\n",
      "[11000]\ttraining's auc: 0.951824\tvalid_1's auc: 0.898327\n",
      "[12000]\ttraining's auc: 0.954971\tvalid_1's auc: 0.898322\n",
      "[13000]\ttraining's auc: 0.957981\tvalid_1's auc: 0.898396\n",
      "Early stopping, best iteration is:\n",
      "[10181]\ttraining's auc: 0.949146\tvalid_1's auc: 0.898482\n",
      "Fold 7\n",
      "[LightGBM] [Info] Number of positive: 18088, number of negative: 161912\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53040\n",
      "[LightGBM] [Info] Number of data points in the train set: 180000, number of used features: 208\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\ttraining's auc: 0.886218\tvalid_1's auc: 0.870418\n",
      "[2000]\ttraining's auc: 0.903554\tvalid_1's auc: 0.884599\n",
      "[3000]\ttraining's auc: 0.914973\tvalid_1's auc: 0.893394\n",
      "[4000]\ttraining's auc: 0.922326\tvalid_1's auc: 0.897097\n",
      "[5000]\ttraining's auc: 0.927897\tvalid_1's auc: 0.899452\n",
      "[6000]\ttraining's auc: 0.932777\tvalid_1's auc: 0.900922\n",
      "[7000]\ttraining's auc: 0.937056\tvalid_1's auc: 0.901643\n",
      "[8000]\ttraining's auc: 0.940978\tvalid_1's auc: 0.902064\n",
      "[9000]\ttraining's auc: 0.944675\tvalid_1's auc: 0.902352\n",
      "[10000]\ttraining's auc: 0.948105\tvalid_1's auc: 0.902399\n",
      "[11000]\ttraining's auc: 0.951375\tvalid_1's auc: 0.902577\n",
      "[12000]\ttraining's auc: 0.954509\tvalid_1's auc: 0.902672\n",
      "[13000]\ttraining's auc: 0.957457\tvalid_1's auc: 0.902546\n",
      "[14000]\ttraining's auc: 0.960349\tvalid_1's auc: 0.902634\n",
      "[15000]\ttraining's auc: 0.963105\tvalid_1's auc: 0.902568\n",
      "[16000]\ttraining's auc: 0.965638\tvalid_1's auc: 0.902562\n",
      "Early stopping, best iteration is:\n",
      "[13608]\ttraining's auc: 0.959217\tvalid_1's auc: 0.902789\n",
      "Fold 8\n",
      "[LightGBM] [Info] Number of positive: 18088, number of negative: 161912\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53040\n",
      "[LightGBM] [Info] Number of data points in the train set: 180000, number of used features: 208\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\ttraining's auc: 0.887136\tvalid_1's auc: 0.862676\n",
      "[2000]\ttraining's auc: 0.904239\tvalid_1's auc: 0.876661\n",
      "[3000]\ttraining's auc: 0.91557\tvalid_1's auc: 0.885319\n",
      "[4000]\ttraining's auc: 0.922985\tvalid_1's auc: 0.88944\n",
      "[5000]\ttraining's auc: 0.928618\tvalid_1's auc: 0.891779\n",
      "[6000]\ttraining's auc: 0.933468\tvalid_1's auc: 0.89317\n",
      "[7000]\ttraining's auc: 0.937747\tvalid_1's auc: 0.894139\n",
      "[8000]\ttraining's auc: 0.941687\tvalid_1's auc: 0.894625\n",
      "[9000]\ttraining's auc: 0.945334\tvalid_1's auc: 0.895012\n",
      "[10000]\ttraining's auc: 0.948792\tvalid_1's auc: 0.895241\n",
      "[11000]\ttraining's auc: 0.952071\tvalid_1's auc: 0.895439\n",
      "[12000]\ttraining's auc: 0.95518\tvalid_1's auc: 0.895359\n",
      "[13000]\ttraining's auc: 0.958178\tvalid_1's auc: 0.895349\n",
      "[14000]\ttraining's auc: 0.961011\tvalid_1's auc: 0.895368\n",
      "Early stopping, best iteration is:\n",
      "[11142]\ttraining's auc: 0.952537\tvalid_1's auc: 0.895505\n",
      "Fold 9\n",
      "[LightGBM] [Info] Number of positive: 18088, number of negative: 161912\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53040\n",
      "[LightGBM] [Info] Number of data points in the train set: 180000, number of used features: 208\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\ttraining's auc: 0.885853\tvalid_1's auc: 0.877196\n",
      "[2000]\ttraining's auc: 0.903558\tvalid_1's auc: 0.890474\n",
      "[3000]\ttraining's auc: 0.914913\tvalid_1's auc: 0.89722\n",
      "[4000]\ttraining's auc: 0.922374\tvalid_1's auc: 0.900927\n",
      "[5000]\ttraining's auc: 0.928072\tvalid_1's auc: 0.902641\n",
      "[6000]\ttraining's auc: 0.932934\tvalid_1's auc: 0.903628\n",
      "[7000]\ttraining's auc: 0.93718\tvalid_1's auc: 0.904231\n",
      "[8000]\ttraining's auc: 0.941164\tvalid_1's auc: 0.904563\n",
      "[9000]\ttraining's auc: 0.944889\tvalid_1's auc: 0.904796\n",
      "[10000]\ttraining's auc: 0.948377\tvalid_1's auc: 0.904895\n",
      "[11000]\ttraining's auc: 0.951642\tvalid_1's auc: 0.904985\n",
      "[12000]\ttraining's auc: 0.954773\tvalid_1's auc: 0.904759\n",
      "[13000]\ttraining's auc: 0.957768\tvalid_1's auc: 0.904916\n",
      "Early stopping, best iteration is:\n",
      "[10610]\ttraining's auc: 0.950399\tvalid_1's auc: 0.905094\n",
      "CV score: 0.89952 \n"
     ]
    }
   ],
   "source": [
    "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=44000)\n",
    "oof = np.zeros(len(train_df))\n",
    "predictions = np.zeros(len(test_df))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "\n",
    "    num_round = 1000000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 3000)\n",
    "    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "70299b2aa81a678c0bee8ca183f064c82b673ba4"
   },
   "source": [
    "Let's check the feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "9f989c0d69a89f3964265615b6c64ad6010cec37"
   },
   "outputs": [],
   "source": [
    "cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n",
    "        .groupby(\"Feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:150].index)\n",
    "best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,28))\n",
    "sns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\n",
    "plt.title('Features importance (averaged/folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('FI.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "94f2cac9789db26b27c88db136d1366c70b5cc33"
   },
   "source": [
    "# <a id='7'>Submission</a>  \n",
    "\n",
    "We submit the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "4c1965242e30db114a3a28d850fea148d34c06c9"
   },
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"ID_code\":test_df[\"ID_code\"].values})\n",
    "sub_df[\"target\"] = predictions\n",
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
